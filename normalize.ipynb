{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86d8823-8aa6-4a03-aec7-1c2c0b23c8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 387/387 [02:50<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path,save_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "\n",
    "        # Save the normalized image\n",
    "        norm_filename = \"norm_\" + os.path.basename(row['img_path'])\n",
    "        directory = os.path.dirname(img_path)\n",
    "        norm_path = os.path.join(directory, norm_filename)\n",
    "        save_nii_image(normalized_image, norm_path, nii_img)\n",
    "\n",
    "        # Update the dataframe\n",
    "        df.at[index, 'norm_path'] = save_path+norm_filename\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "save_path =\"/Train/ixi/t1/\"\n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/patched-Diffusion-Models-UAD/Data/splits/IXI_train_fold0.csv\"\n",
    "process_images_and_save(base_dir, csv_path,save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87416fa-f680-4e97-b6ce-1ee33ec88e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 4820/4820 [47:26<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "\n",
    "        # Save the normalized image\n",
    "        norm_filename = \"norm_\" + os.path.basename(row['img_path'])\n",
    "        directory = os.path.dirname(img_path)\n",
    "        norm_path = os.path.join(directory, norm_filename)\n",
    "        save_nii_image(normalized_image, norm_path, nii_img)\n",
    "\n",
    "        # Update the dataframe\n",
    "        df.at[index, 'norm_path'] = save_path+norm_filename\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example usa\n",
    "save_path =\"/Train/BioBank/t1/\"\n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/patched-Diffusion-Models-UAD/Data/splits/BioBank_train.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef7a1fd-9a56-4a58-ad93-04735f4e0fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 44/44 [00:29<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "\n",
    "        # Save the normalized image\n",
    "        norm_filename = \"norm_\" + os.path.basename(row['img_path'])\n",
    "        directory = os.path.dirname(img_path)\n",
    "        norm_path = os.path.join(directory, norm_filename)\n",
    "        save_nii_image(normalized_image, norm_path, nii_img)\n",
    "\n",
    "        # Update the dataframe\n",
    "        df.at[index, 'norm_path'] =save_path+ norm_filename\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example usa\n",
    "save_path =\"/Train/ixi/t1/\"\n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/patched-Diffusion-Models-UAD/Data/splits/IXI_val_fold0.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5de546-4221-45d3-9fdf-c0730143967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [01:02<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "\n",
    "        # Save the normalized image\n",
    "        norm_filename = \"norm_\" + os.path.basename(row['img_path'])\n",
    "        directory = os.path.dirname(img_path)\n",
    "        norm_path = os.path.join(directory, norm_filename)\n",
    "        save_nii_image(normalized_image, norm_path, nii_img)\n",
    "\n",
    "        # Update the dataframe\n",
    "        df.at[index, 'norm_path'] = save_path+norm_filename\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example usa\n",
    "save_path =\"/Test/Brats21/t1/\"\n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/patched-Diffusion-Models-UAD/Data/splits/Brats21_sub_test.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ced225-f9df-4e14-a095-e2646fc382bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "\n",
    "        # Save the normalized image\n",
    "        norm_filename = \"norm_\" + os.path.basename(row['img_path'])\n",
    "        directory = os.path.dirname(img_path)\n",
    "        norm_path = os.path.join(directory, norm_filename)\n",
    "        save_nii_image(normalized_image, norm_path, nii_img)\n",
    "\n",
    "        # Update the dataframe\n",
    "        df.at[index, 'norm_path'] = save_path+norm_filename\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example usa\n",
    "save_path =\"/Train/HCP/t1/\"\n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/patched-Diffusion-Models-UAD/Data/splits/Brats21_sub_test.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2fac1c-e848-477e-848c-ea0994550a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 6973/6973 [1:02:48<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example \n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/3D_lesion_DF/Data/splits/combined_4datasets.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb501fa-c3fc-4a3e-b799-c0eac044fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 160/160 [01:36<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example \n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/3D_lesion_DF/Data/splits/IXI_test.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8063d347-1236-4be8-be02-17967e501c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 99/99 [00:57<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib  # Make sure to install nibabel in your environment\n",
    "\n",
    "# Mock function to simulate loading a .nii image\n",
    "def load_nii_image(path):\n",
    "    # Load the .nii image using nibabel\n",
    "    nii_img = nib.load(path)\n",
    "    return nii_img.get_fdata()\n",
    "\n",
    "def save_nii_image(data, save_path, reference_nii):\n",
    "    # Save the numpy data as .nii image using nibabel\n",
    "    new_nii = nib.Nifti1Image(data, reference_nii.affine, reference_nii.header)\n",
    "    nib.save(new_nii, save_path)\n",
    "\n",
    "def normalize_by_peak(image):\n",
    "    image[image<0] = 0\n",
    "    hist, bins = np.histogram(image, bins=20)\n",
    "    peak = bins[np.argmax(hist[1:])+1]\n",
    "    normalized_image = image / peak\n",
    "    return normalized_image, peak\n",
    "\n",
    "def process_images_and_save(base_dir, csv_path):\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Add new columns to the dataframe\n",
    "    df['norm_path'] = ''\n",
    "    df['peak'] = 0\n",
    "\n",
    "    # Wrap the loop with tqdm for progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing images\"):\n",
    "        # Load the .nii image\n",
    "        img_path = os.path.join(base_dir, row['img_path'].lstrip('/'))\n",
    "        # print(row['img_path'])\n",
    "        # print(base_dir)\n",
    "        # print(img_path)\n",
    "        nii_img = nib.load(img_path)\n",
    "        image = nii_img.get_fdata()\n",
    "\n",
    "        # Normalize the image and get the peak\n",
    "        normalized_image, peak = normalize_by_peak(image)\n",
    "        df.at[index, 'peak'] = peak\n",
    "\n",
    "    # Save the updated CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Example \n",
    "base_dir = \"/scratch1/akrami/Data_train\"\n",
    "csv_path = \"/project/ajoshi_27/akrami/3D_lesion_DF/Data/splits/BioBank_val.csv\"\n",
    "process_images_and_save(base_dir, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6723c-b3e1-489a-b4e3-ea01d4ea7aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_monai",
   "language": "python",
   "name": "working_monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
