{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edbb9a6-8e79-44e9-b13a-4f31dc7ab68e",
   "metadata": {},
   "source": [
    "# Get all files names in the direcotry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33ca636-27e7-45fa-abe3-41938b3230ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def list_subdirectories(directory_path):\n",
    "    return [os.path.join(directory_path, d, \"nu_T1_brain_6dof2Ref.nii.gz\") for d in os.listdir(directory_path) ]\n",
    "\n",
    "def write_to_csv(subdirectories):\n",
    "    with open('biobank.csv', 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['img_path'])  # Column header\n",
    "        for subdir in subdirectories:\n",
    "            csvwriter.writerow([subdir])\n",
    "\n",
    "# Example usage:\n",
    "directory_path = \"/scratch1/ajoshi/BrainAge_Preproc_FS7.1.1/\"\n",
    "subdirs = list_subdirectories(directory_path)\n",
    "write_to_csv(subdirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf8b282-7b46-4f7e-8d50-08a0b92941d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def k_fold_cross_validation_from_csv(input_file, column_name, k, output_dir):\n",
    "    \"\"\"\n",
    "    Splits the data from the specified column of the input CSV file into k folds for cross-validation \n",
    "    and writes them to separate CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file: Path to the input CSV file.\n",
    "    - column_name: The name of the column from which to select samples.\n",
    "    - k: Number of folds for cross-validation.\n",
    "    - output_dir: Directory where the output CSV files will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Check if the column exists\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in {input_file}\")\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Split the data into k parts\n",
    "    fold_size = len(df) // k\n",
    "    folds = [df.iloc[i * fold_size: (i + 1) * fold_size] for i in range(k)]\n",
    "    \n",
    "    # Handle any remaining samples if the dataset size is not perfectly divisible by k\n",
    "    for i in range(len(df) % k):\n",
    "        folds[i] = folds[i].append(df.iloc[-(i+1)])\n",
    "    \n",
    "    # For each fold, save the training and test sets to separate files\n",
    "    for i in range(k):\n",
    "        test = folds[i]\n",
    "        train = pd.concat([folds[j] for j in range(k) if j != i], ignore_index=True)\n",
    "        \n",
    "        test_file = os.path.join(output_dir, f\"Biobank_test_fold_{i+1}.csv\")\n",
    "        train_file = os.path.join(output_dir, f\"Biobank_train_fold_{i+1}.csv\")\n",
    "        \n",
    "        test[[column_name]].to_csv(test_file, index=False)\n",
    "        train[[column_name]].to_csv(train_file, index=False)\n",
    "\n",
    "# For demonstration, we will not run the function yet.\n",
    "# k_fold_cross_validation_from_csv('biobank.csv', 'img_path', 5, 'output_directory_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e39c05-ff4a-4fb9-8712-f34fc4a778f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_16829085/ipykernel_8682/512982690.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  folds[i] = folds[i].append(df.iloc[-(i+1)])\n",
      "/tmp/SLURM_16829085/ipykernel_8682/512982690.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  folds[i] = folds[i].append(df.iloc[-(i+1)])\n",
      "/tmp/SLURM_16829085/ipykernel_8682/512982690.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  folds[i] = folds[i].append(df.iloc[-(i+1)])\n",
      "/tmp/SLURM_16829085/ipykernel_8682/512982690.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  folds[i] = folds[i].append(df.iloc[-(i+1)])\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "import pandas as pd\n",
    "#csv_path = 'biobank.csv'\n",
    "#df = pd.read_csv(csv_path)\n",
    "k_fold_cross_validation_from_csv('biobank.csv', 'img_path', 5, './')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d9f79-8bbd-4fbd-bc1a-e3299fcc0d4a",
   "metadata": {},
   "source": [
    "# Generate a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f14deb-d8e5-4916-a27b-a7044695e5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45464\n",
      "40464\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def random_sample_from_csv(input_file, column_name, n, output_file, exclude_file):\n",
    "    \"\"\"\n",
    "    Randomly selects n samples from the specified column of the input CSV file\n",
    "    and writes them to a new CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file: Path to the input CSV file.\n",
    "    - column_name: The name of the column from which to select samples.\n",
    "    - n: The number of random samples to select.\n",
    "    - output_file: Path to the output CSV file.\n",
    "    - exclude_file: Path to the CSV file containing image paths to exclude.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV files\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(len(df))\n",
    "    exclude_df = pd.read_csv(exclude_file)\n",
    "    \n",
    "    # Convert the exclude DataFrame to a list\n",
    "    exclude_list = exclude_df[column_name].tolist()\n",
    "    \n",
    "    # Filter out the rows with image paths that are in the exclude list\n",
    "    filtered_df = df[~df[column_name].isin(exclude_list)]\n",
    "    print(len(filtered_df))\n",
    "    # Check if the column exists\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in {input_file}\")\n",
    "    \n",
    "    # Check if there are enough rows to sample\n",
    "    if n > len(filtered_df):\n",
    "        raise ValueError(f\"Cannot sample {n} rows from a dataset of {len(filtered_df)} rows after excluding\")\n",
    "    \n",
    "    # Randomly sample n rows from the column of the filtered DataFrame\n",
    "    samples = random.sample(list(filtered_df[column_name]), n)\n",
    "    \n",
    "    # Convert samples to DataFrame\n",
    "    samples_df = pd.DataFrame(samples, columns=[column_name])\n",
    "    \n",
    "    # Write to the output CSV file\n",
    "    samples_df.to_csv(output_file, index=False)\n",
    "\n",
    "random_sample_from_csv('biobank.csv', 'img_path', 100, 'subset_val_biobank.csv', 'subset_biobank.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171e0e7-b9f2-40a1-a7c3-d441fb2ec759",
   "metadata": {},
   "source": [
    "# Copy anr rename subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f16022-89c9-488c-bb70-2cfb481f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Read the CSV file\n",
    "csv_path = 'subset_val_biobank.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Specify the column name containing the file paths\n",
    "column_name = 'img_path'\n",
    "\n",
    "# Create the T1 directory if it doesn't exist\n",
    "dir = '/scratch1/akrami/Latest_Data/Data_pre/BioBank_val/t1/'\n",
    "\n",
    "# Process each file path\n",
    "for file_path in df[column_name]:\n",
    "    # Check if the file exists\n",
    "   \n",
    "    if os.path.exists(file_path):\n",
    "        # Extract the subname from the file path\n",
    "        full_subname = os.path.basename(os.path.dirname(file_path))\n",
    "        # Extract only the desired part of the subname (before the first underscore)\n",
    "        main_subname = full_subname.split('_')[0]\n",
    "        # Define the destination path\n",
    "        dest_path_sub = f'{main_subname}_t1.nii.gz'\n",
    "        dest_path = dir+ dest_path_sub\n",
    "        # Copy the file to the destination\n",
    "        shutil.copy(file_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e966f-85e1-4080-88ae-2b2e77de42db",
   "metadata": {},
   "source": [
    "# files which are not there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2875d4-587b-4de7-bfbb-e981e633fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Read the CSV file\n",
    "csv_path = 'subset_biobank.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Specify the column name containing the file paths\n",
    "column_name = 'img_path'\n",
    "\n",
    "# Create the T1 directory if it doesn't exist\n",
    "dir = '/scratch1/akrami/Latest_Data/Data_pre/BioBank/t1/'\n",
    "\n",
    "# Process each file path\n",
    "for file_path in df[column_name]:\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(file_path)\n",
    "    # if os.path.exists(file_path):\n",
    "    #     # Extract the subname from the file path\n",
    "    #     full_subname = os.path.basename(os.path.dirname(file_path))\n",
    "    #     # Extract only the desired part of the subname (before the first underscore)\n",
    "    #     main_subname = full_subname.split('_')[0]\n",
    "    #     # Define the destination path\n",
    "    #     dest_path_sub = f'{main_subname}_t1.nii.gz'\n",
    "    #     dest_path = dir+ dest_path_sub\n",
    "    #     # Copy the file to the destination\n",
    "    #     shutil.copy(file_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757127e5-affc-45f3-93a2-ffa227eaaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the source CSV\n",
    "source_csv_path = \"/project/ajoshi_27/akrami//patched-Diffusion-Models-UAD/Data/splits/BioBank_train.csv\"\n",
    "df = pd.read_csv(source_csv_path, nrows=200)\n",
    "\n",
    "# Write the first 200 rows to a new CSV\n",
    "output_csv_path = \"/project/ajoshi_27/akrami//patched-Diffusion-Models-UAD/Data/splits/BioBank_small.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb1b47-664d-4754-9b2c-f349008cb42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_monai",
   "language": "python",
   "name": "working_monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
