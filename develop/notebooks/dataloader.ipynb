{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f223d5-7532-4021-b16a-4c0c14a0d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import unet\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torchio as tio\n",
    "sitk.ProcessObject.SetGlobalDefaultThreader(\"Platform\")\n",
    "from multiprocessing import Manager\n",
    "import configparser\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29c154-571a-456b-9cbd-b14036d9107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 5,\n",
    "    'imgDimResize': (208, 248, 208),\n",
    "    'imgDimPad': (208, 256, 208),\n",
    "    'spatialDims': '2D',\n",
    "    'unisotropic_sampling': True, \n",
    "    'perc_low': 1, \n",
    "    'perc_high': 99, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cc9b4-0897-42ea-9c29-601965ccf930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(csv,cfg,preload=True):\n",
    "    subjects = []\n",
    "    for _, sub in csv.iterrows():\n",
    "        subject_dict = {\n",
    "            'vol' : tio.ScalarImage(sub.img_path, reader=sitk_reader), \n",
    "            'age' : sub.age,\n",
    "            'sex' : sub.sex,\n",
    "            'Dataset' : sub.Dataset,\n",
    "            'ID' : sub.ID,\n",
    "            'path' : sub.img_path\n",
    "        }\n",
    "\n",
    "        subject = tio.Subject(subject_dict)\n",
    "        subjects.append(subject)\n",
    "    \n",
    "    if preload: \n",
    "        manager = Manager()\n",
    "        cache = DatasetCache(manager)\n",
    "        ds = tio.SubjectsDataset(subjects, transform = get_transform(cfg))\n",
    "        ds = preload_wrapper(ds, cache, augment = get_augment(cfg))\n",
    "    else: \n",
    "        ds = tio.SubjectsDataset(subjects, transform = tio.Compose([get_transform(cfg),get_augment(cfg)]))\n",
    "        \n",
    "    if cfg.get('spatialDims') == '2D':\n",
    "        slice_ind = cfg.get('startslice',None) \n",
    "        seq_slices = cfg.get('sequentialslices',None) \n",
    "        ds = vol2slice(ds,cfg,slice=slice_ind,seq_slices=seq_slices)\n",
    "    return ds\n",
    "\n",
    "def sitk_reader(path):\n",
    "                \n",
    "    image_nii = sitk.ReadImage(str(path), sitk.sitkFloat32)\n",
    "    vol = sitk.GetArrayFromImage(image_nii).transpose(2,1,0)\n",
    "    return vol, None\n",
    "\n",
    "\n",
    "def get_transform(cfg): # only transforms that are applied once before preloading\n",
    "        \n",
    "    if cfg.get('unisotropic_sampling',True):\n",
    "        preprocess = tio.Compose([\n",
    "        tio.Resize(cfg.get('imageDimResize',(208, 248, 208))),\n",
    "        tio.CropOrPad(cfg.get('imageDimPad',(208, 256, 208)),padding_mode=0),\n",
    "        tio.RescaleIntensity((0, 1),percentiles=(cfg.get('perc_low',1),cfg.get('perc_high',99))),\n",
    "        ])\n",
    "\n",
    "    else: \n",
    "        preprocess = tio.Compose([\n",
    "                tio.RescaleIntensity((0, 1),percentiles=(cfg.get('perc_low',1),cfg.get('perc_high',99))),\n",
    "                tio.Resample(cfg.get('rescaleFactor',3.0),image_interpolation='bspline',exclude=exclude_from_resampling),#,exclude=['vol_orig','mask_orig','seg_orig']), # we do not want to resize *_orig volumes\n",
    "            ])\n",
    "\n",
    "\n",
    "    return preprocess\n",
    "\n",
    "class DatasetCache(object):\n",
    "    def __init__(self, manager, use_cache=True):\n",
    "        self.use_cache = use_cache\n",
    "        self.manager = manager\n",
    "        self._dict = manager.dict()\n",
    "\n",
    "    def is_cached(self, key):\n",
    "        if not self.use_cache:\n",
    "            return False\n",
    "        return str(key) in self._dict\n",
    "\n",
    "    def reset(self):\n",
    "        self._dict.clear()\n",
    "\n",
    "    def get(self, key):\n",
    "        if not self.use_cache:\n",
    "            raise AttributeError('Data caching is disabled and get funciton is unavailable! Check your config.')\n",
    "        return self._dict[str(key)]\n",
    "\n",
    "    def cache(self, key, subject):\n",
    "        # only store if full data in memory is enabled\n",
    "        if not self.use_cache:\n",
    "            return\n",
    "        # only store if not already cached\n",
    "        if str(key) in self._dict:\n",
    "            return\n",
    "        self._dict[str(key)] = (subject)\n",
    "\n",
    "class preload_wrapper(Dataset):\n",
    "    def __init__(self,ds,cache,augment=None):\n",
    "            self.cache = cache\n",
    "            self.ds = ds\n",
    "            self.augment = augment\n",
    "    def reset_memory(self):\n",
    "        self.cache.reset()\n",
    "    def __len__(self):\n",
    "            return len(self.ds)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.cache.is_cached(index) :\n",
    "            subject = self.cache.get(index)\n",
    "        else:\n",
    "            subject = self.ds.__getitem__(index)\n",
    "            self.cache.cache(index, subject)\n",
    "        if self.augment:\n",
    "            subject = self.augment(subject)\n",
    "        return subject\n",
    "    \n",
    "class vol2slice(Dataset):\n",
    "    def __init__(self,ds,cfg,onlyBrain=False,slice=None,seq_slices=None):\n",
    "            self.ds = ds\n",
    "            self.onlyBrain = onlyBrain\n",
    "            self.slice = slice\n",
    "            self.seq_slices = seq_slices\n",
    "            self.counter = 0 \n",
    "            self.ind = None\n",
    "            self.cfg = cfg\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.ds)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        subject = self.ds.__getitem__(index)\n",
    "        \n",
    "        #Commenting the next few lines to introduce a simple masking operation\n",
    "#         if self.onlyBrain:\n",
    "#             start_ind = None\n",
    "#             for i in range(subject['vol'].data.shape[-1]):\n",
    "#                 if subject['mask'].data[0,:,:,i].any() and start_ind is None: # only do this once\n",
    "#                     start_ind = i \n",
    "#                 if not subject['mask'].data[0,:,:,i].any() and start_ind is not None: # only do this when start_ind is set\n",
    "#                     stop_ind = i \n",
    "#             low = start_ind\n",
    "#             high = stop_ind\n",
    "#         else: \n",
    "#             low = 0\n",
    "#             high = subject['vol'].data.shape[-1]\n",
    "#         if self.slice is not None:\n",
    "#             self.ind = self.slice\n",
    "#             if self.seq_slices is not None:\n",
    "#                 low = self.ind\n",
    "#                 high = self.ind + self.seq_slices\n",
    "#                 self.ind = torch.randint(low,high,size=[1])\n",
    "#         else:\n",
    "#             if self.cfg.get('unique_slice',False): # if all slices in one batch need to be at the same location\n",
    "#                 if self.counter % self.cfg.batch_size == 0 or self.ind is None: # only change the index when changing to new batch\n",
    "#                     self.ind = torch.randint(low,high,size=[1])\n",
    "#                 self.counter = self.counter +1\n",
    "#             else: \n",
    "#                 self.ind = torch.randint(low,high,size=[1])\n",
    "\n",
    "#         subject['ind'] = self.ind\n",
    "\n",
    "#         subject['vol'].data = subject['vol'].data[...,self.ind]\n",
    "#         subject['mask'].data = subject['mask'].data[...,self.ind]\n",
    "\n",
    "\n",
    "        subject['vol'].data = subject['vol'].data.permute(0,3, 2, 1)\n",
    "    \n",
    "        #msk_normal = ~np.all(subject['vol'].data.numpy()[0] == 0,axis=(1,2)) # Remove empty planes (Replacing this line of code to include slices that have significant prain volume in them (more than 15% of the image is brain))\n",
    "        \n",
    "        msk_normal = (np.count_nonzero(subject['vol'].data.numpy()[0],axis=(1,2))/(subject['vol'].data.numpy()[0].shape[1]*subject['vol'].data.numpy()[0].shape[2]))>=0.15\n",
    "        \n",
    "        choices = np.arange(len(msk_normal))[msk_normal]\n",
    "        \n",
    "        sample_idx = np.array(random.choices(choices,k = 1))\n",
    "        \n",
    "        subject['vol'].data = subject['vol'].data[0:2, sample_idx, ...]\n",
    "\n",
    "        return subject\n",
    "\n",
    "def get_augment(cfg): # augmentations that may change every epoch\n",
    "    augmentations = []\n",
    "\n",
    "    # individual augmentations\n",
    "    augment = tio.Compose(augmentations)\n",
    "    return augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab78f0-1f2d-42c9-9af4-b42ec60ecf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Train(pd.read_csv('./data/zamzam/train.csv', converters={'img_path': pd.eval}), config)\n",
    "train_loader = DataLoader(data_train, batch_size=config.get('batch_size', 1),shuffle=True,num_workers=1)\n",
    "\n",
    "data_val = Train(pd.read_csv('/scratch1/zamzam/val.csv', converters={'img_path': pd.eval}), config)\n",
    "val_loader = DataLoader(data_train, batch_size=config.get('batch_size', 1),shuffle=True,num_workers=1)\n",
    "\n",
    "data_test = Train(pd.read_csv('/scratch1/zamzam/test.csv', converters={'img_path': pd.eval}), config)\n",
    "test_loader = DataLoader(data_train, batch_size=config.get('batch_size', 1),shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dac638-8aaf-4778-8bb2-34e995b79a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b892d-70f5-4893-a0da-4fee1e712bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.keys())\n",
    "print(s['age'])\n",
    "print(s['Dataset'])\n",
    "print(s['sex'])\n",
    "print(s['vol']['data'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f34625-1634-4240-83f6-d05f44049942",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = s['vol']['data'][0][0].squeeze().cpu().numpy()\n",
    "plt.imshow(image_array, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fdbc46-93aa-40ce-b52c-2d0892e92c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_monai",
   "language": "python",
   "name": "working_monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
