{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import io\n",
    "import monai\n",
    "import random\n",
    "import tempfile\n",
    "from multiprocessing import Manager\n",
    "from tqdm.notebook import tqdm\n",
    "from monai.config import USE_COMPILED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "from monai.networks.nets import UNet\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# MONAI Libraries\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "# from monai.transforms import (\n",
    "#     AddChanneld, \n",
    "#     CenterSpatialCropd, \n",
    "#     Compose, \n",
    "#     Lambdad, \n",
    "#     LoadImaged, \n",
    "#     Resized, \n",
    "#     ScaleIntensityd\n",
    "# )\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# Custom Libraries\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "from generative.networks.schedulers import DDPMScheduler, DDIMScheduler\n",
    "from dataloader import Train ,Eval \n",
    "\n",
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (8192, rlimit[1]))\n",
    "\n",
    "print(\"This is registration job.\")\n",
    "# import wandb\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"Registration\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"Data\": \"4 datasets (4000 random samples)\",\n",
    "#     \"Loss\": \"MSE\", \n",
    "#     \"reg_penalty\": \"0.000001\",\n",
    "#     \"lr\": \"0.0001\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# Configuration\n",
    "sitk.ProcessObject.SetGlobalDefaultThreader(\"Platform\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "JUPYTER_ALLOW_INSECURE_WRITES=True\n",
    "\n",
    "\n",
    "# Initialize Configuration\n",
    "config = {\n",
    "    'batch_size': 2,\n",
    "    'imgDimResize': (160, 192, 160),\n",
    "    'imgDimPad': (208, 256, 208),\n",
    "    'spatialDims': '3D',\n",
    "    'unisotropic_sampling': True,\n",
    "    'perc_low': 1,\n",
    "    'perc_high': 99,\n",
    "    'rescaleFactor': 2,\n",
    "    'base_path': '/scratch1/akrami/Latest_Data/Data',\n",
    "    'lambda': 100,\n",
    "}\n",
    "\n",
    "# Seed and Device Configuration\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# CUDA and CUDNN Configuration\n",
    "# Uncomment the following line to specify CUDA_VISIBLE_DEVICES\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,5,6'\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# SimpleITK Configuration\n",
    "# Set the default number of threads and global behavior for SimpleITK\n",
    "sitk.ProcessObject.SetGlobalDefaultThreader(\"Platform\")\n",
    "    \n",
    "data_train = Train(pd.read_csv('./LesionData/train.csv'),config) \n",
    "data_val = Train(pd.read_csv('./LesionData/val.csv'),config)                \n",
    "\n",
    "\n",
    "\n",
    "# #data_train = Train(pd.read_csv('/project/ajoshi_27/akrami/monai3D/GenerativeModels/data/split/IXI_train_fold0.csv', converters={'img_path': pd.eval}), config)\n",
    "train_loader = DataLoader(data_train, batch_size=config.get('batch_size', 2),shuffle=True)\n",
    "\n",
    "#data_val = Train(pd.read_csv('/project/ajoshi_27/akrami/monai3D/GenerativeModels/data/split/IXI_val_fold0.csv', converters={'img_path': pd.eval}), config)\n",
    "val_loader = DataLoader(data_val, batch_size=config.get('batch_size', 2),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    num_channels=(64, 64, 64),\n",
    "    attention_levels=(False, False, True),\n",
    "    num_res_blocks=1,\n",
    "    num_head_channels=64,\n",
    "    with_conditioning=False,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "inferer = DiffusionInferer(scheduler)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 500\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        input_data = data['vol']['data']\n",
    "        input_data = input_data.to(device)\n",
    "        peak_expanded = (data['peak'].unsqueeze(1).unsqueeze(2).unsqueeze(3).unsqueeze(4)).long().to(device)\n",
    "        input_data = (input_data / peak_expanded)\n",
    "        groundtruth = input_data.detach()\n",
    "        masks = data['mask']['data']\n",
    "        masks = masks.to(device)\n",
    "        masked_input_data = (input_data*torch.where((masks == 0) , 1, 0)).detach()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        timesteps = torch.randint(0, 1000, (len(input_data),)).to(device)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            # Generate random noise\n",
    "            noise = torch.randn_like(groundtruth).to(device)\n",
    "            noisy_groundtruth = scheduler.add_noise(\n",
    "                original_samples=groundtruth, noise=noise, timesteps=timesteps\n",
    "            )  # we only add noise to the segmentation mask\n",
    "            combined = torch.cat(\n",
    "                (masked_input_data, noisy_groundtruth), dim=1\n",
    "            )  # we concatenate the brain MR image with the noisy segmenatation mask, to condition the generation process\n",
    "            prediction = model(x=combined, timesteps=timesteps)\n",
    "            # Get model prediction\n",
    "            loss = F.mse_loss(prediction.float(), noise.float())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "          \n",
    "    print('  * train  ' +\n",
    "        f'Loss: {epoch_loss/len(train_loader):.7f}, ')\n",
    "\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    for i, data in enumerate(tqdm(val_loader)):\n",
    "\n",
    "        input_data = data['vol']['data']\n",
    "        input_data = input_data.to(device)\n",
    "        groundtruth = input_data\n",
    "        peak_expanded = (data['peak'].unsqueeze(1).unsqueeze(2).unsqueeze(3).unsqueeze(4)).long().to(device)\n",
    "        input_data = (input_data / peak_expanded)\n",
    "        masks = data['mask']['data']\n",
    "        masks = masks.to(device)\n",
    "        masked_input_data = input_data*torch.where((masks == 0) , 1, 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "                with autocast(enabled=True):\n",
    "                    noise = torch.randn_like(groundtruth).to(device)\n",
    "                    noisy_groundtruth = scheduler.add_noise(original_samples=groundtruth, noise=noise, timesteps=timesteps)\n",
    "                    combined = torch.cat((masked_input_data, noisy_groundtruth), dim=1)\n",
    "                    prediction = model(x=combined, timesteps=timesteps)\n",
    "                    val_loss = F.mse_loss(prediction.float(), noise.float())\n",
    "            val_epoch_loss += val_loss.item()\n",
    "        #print(\"Epoch\", epoch, \"Validation loss\", val_epoch_loss / (step + 1))\n",
    "        print('  * val  ' +\n",
    "          f'Loss: {val_epoch_loss/len(val_loader):.7f}, ')\n",
    "    \n",
    "    if (epoch%1==0):\n",
    "        torch.save(model.state_dict(), f\"./model{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn_like(input_data).to(device)\n",
    "current_img = noise  # for the segmentation mask, we start from random noise.\n",
    "combined = torch.cat(\n",
    "    (masked_input_data, noise), dim=1\n",
    ")  # We concatenate the input brain MR image to add anatomical information.\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps=1000)\n",
    "progress_bar = tqdm(scheduler.timesteps)\n",
    "chain = torch.zeros(current_img.shape)\n",
    "for t in progress_bar:  # go through the noising process\n",
    "    with autocast(enabled=False):\n",
    "        with torch.no_grad():\n",
    "            model_output = model(combined, timesteps=torch.Tensor((t,)).to(current_img.device))\n",
    "            current_img, _ = scheduler.step(\n",
    "                model_output, t, current_img\n",
    "            )  # this is the prediction x_t at the time step t\n",
    "            combined = torch.cat(\n",
    "                (masked_input_data, current_img), dim=1\n",
    "            )  # in every step during"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working_monai_v2",
   "language": "python",
   "name": "working_monai_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
